日本語フォント設定: Osaka
=== LightGBM競馬3着以内予測 実行開始 ===
=== fetch_data_time_split関数 実行開始 ===
メインデータ取得開始
odds1_tansho取得開始
odds1_fukusho取得開始
keito_joho2取得開始
bataiju取得開始
kishu_master取得開始
race_shosai取得開始
前走情報JOIN開始
直近3走の着順平均・人気平均計算
【fetch_data_time_split関数 実行所要時間】64.11秒
オーバーサンプリング前: [7643 1985]
SMOTE後: [7643 7643]
Training until validation scores don't improve for 20 rounds
[20]	train's binary_logloss: 0.513707	train's auc: 0.9304	train's average_precision: 0.931805	valid's binary_logloss: 0.506532	valid's auc: 0.939979	valid's average_precision: 0.848599
[40]	train's binary_logloss: 0.425498	train's auc: 0.935807	train's average_precision: 0.93762	valid's binary_logloss: 0.409836	valid's auc: 0.944288	valid's average_precision: 0.85971
[60]	train's binary_logloss: 0.375526	train's auc: 0.939436	train's average_precision: 0.941195	valid's binary_logloss: 0.352934	valid's auc: 0.947646	valid's average_precision: 0.866753
[80]	train's binary_logloss: 0.343964	train's auc: 0.943671	train's average_precision: 0.945241	valid's binary_logloss: 0.315411	valid's auc: 0.950403	valid's average_precision: 0.873369
[100]	train's binary_logloss: 0.323567	train's auc: 0.946524	train's average_precision: 0.947827	valid's binary_logloss: 0.292205	valid's auc: 0.951751	valid's average_precision: 0.875403
Early stopping, best iteration is:
[87]	train's binary_logloss: 0.335106	train's auc: 0.944893	train's average_precision: 0.946344	valid's binary_logloss: 0.304464	valid's auc: 0.951515	valid's average_precision: 0.876033
重要度下位30%の特徴量を除外: ['WAKUBAN_te', 'SEIBETSU_CODE', 'FUTAN_JURYO']
Training until validation scores don't improve for 20 rounds
[20]	train's binary_logloss: 0.514861	train's auc: 0.929061	train's average_precision: 0.931119	valid's binary_logloss: 0.51136	valid's auc: 0.938524	valid's average_precision: 0.846487
Early stopping, best iteration is:
[7]	train's binary_logloss: 0.614448	train's auc: 0.923211	train's average_precision: 0.925627	valid's binary_logloss: 0.611936	valid's auc: 0.939148	valid's average_precision: 0.850193
[再学習] Recall>=0.85となる最小閾値: 0.510
[再学習] --- Recall重視評価（閾値=0.510） ---
Accuracy: 0.8679
F1 Score: 0.7305
Recall: 0.8501
PR-AUC: 0.8502
Confusion Matrix:
[[1659  242]
 [  76  431]]
              precision    recall  f1-score   support

           0       0.96      0.87      0.91      1901
           1       0.64      0.85      0.73       507

    accuracy                           0.87      2408
   macro avg       0.80      0.86      0.82      2408
weighted avg       0.89      0.87      0.87      2408

Recall>=0.85となる最小閾値: 0.541
--- Recall重視評価（閾値=0.541） ---
Accuracy: 0.9045
F1 Score: 0.7894
Recall: 0.8501
PR-AUC: 0.8760
Confusion Matrix:
[[1747  154]
 [  76  431]]
              precision    recall  f1-score   support

           0       0.96      0.92      0.94      1901
           1       0.74      0.85      0.79       507

    accuracy                           0.90      2408
   macro avg       0.85      0.88      0.86      2408
weighted avg       0.91      0.90      0.91      2408

--- GPT-4.1からの改善アドバイス ---
モデルの評価と各種グラフを総合的に分析した上で、LightGBMによる競馬の3着以内予測モデル改善のためのアドバイスを簡潔にまとめます。

【1. 評価指標・全体傾向の確認】
- リコール（Recall）重視：0.85（3着以内を比較的多く拾えている）
- 適合率（Precision）：0.74（拾った3着以内のうち正解は7割強）
- F1スコア：0.79
- 精度（Accuracy）：0.90
- 混同行列より3着以内（陽性）の見逃し（FN）は少なめ、誤検知（FP）はやや多い
- ROC曲線はAUCが高い傾向（=判別力はある）
- PR曲線もまずまず（=陽性ラベルの再現性は高いが、Precisionに課題）

【2. 学習曲線・過学習傾向】
- 学習曲線（learning_curve.png）から、訓練・検証のスコア収束は見られるが、若干のギャップあり → わずかな過学習が疑われる

【3. 改善アドバイス】

① 特徴量の見直し
- Feature ImportanceやSHAP値の確認を行い、効果の薄い特徴量を削除や統合。新たな競馬特有特徴量（例: 騎手、馬場状態、過去実績、枠順など）を追加検討。

② データバランスの調整
- 3着以内のラベル（1）は全体の約2割程度で不均衡気味。SMOTE等のオーバーサンプリングやアンダーサンプリング、またはLightGBMの`scale_pos_weight`パラメータ調整でバランス改善。

③ モデルパラメータの最適化
- `num_leaves`や`min_data_in_leaf`、`max_depth`のチューニングで過学習を抑制しつつ再現率を維持。
- Early Stoppingやクロスバリデーションを活用、過学習対策を強化。

④ アンサンブル/他手法の検討
- XGBoostやCatBoost、あるいはロジスティック回帰・ランダムフォレストとのアンサンブルで精度・再現率バランス向上を検討。

⑤ 閾値調整の再検討
- 現在Recall重視（閾値0.54）だが、業務要件/目的に応じてF1やPrecision重視の閾値も検証し、最適なバランスを探索。

⑥ 可視化・解釈性強化
- SHAPやLIMEによる予測根拠の可視化で、モデルの説得力・納得感を向上。

【まとめ】
現状、3着以内をよく拾えているが、Precision向上と過学習抑制が今後の主な改善ポイントです。特徴量工夫・データバランス調整・パラメータ最適化・アンサンブル化で全体性能の底上げを目指しましょう。
【実行所要時間】91.59秒
