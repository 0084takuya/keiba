日本語フォント設定: Osaka
=== LightGBM競馬3着以内予測 実行開始 ===
=== fetch_data_time_split関数 実行開始 ===
メインデータ取得開始
odds1_tansho取得開始
odds1_fukusho取得開始
keito_joho2取得開始
bataiju取得開始
kishu_master取得開始
race_shosai取得開始
前走情報JOIN開始
直近3走の着順平均・人気平均計算
【fetch_data_time_split関数 実行所要時間】63.47秒
オーバーサンプリング前: [7643 1985]
SMOTE後: [7643 7643]
Training until validation scores don't improve for 20 rounds
[20]	train's binary_logloss: 0.513707	train's auc: 0.9304	train's average_precision: 0.931805	valid's binary_logloss: 0.506532	valid's auc: 0.939979	valid's average_precision: 0.848599
[40]	train's binary_logloss: 0.425498	train's auc: 0.935807	train's average_precision: 0.93762	valid's binary_logloss: 0.409836	valid's auc: 0.944288	valid's average_precision: 0.85971
[60]	train's binary_logloss: 0.375526	train's auc: 0.939436	train's average_precision: 0.941195	valid's binary_logloss: 0.352934	valid's auc: 0.947646	valid's average_precision: 0.866753
[80]	train's binary_logloss: 0.343964	train's auc: 0.943671	train's average_precision: 0.945241	valid's binary_logloss: 0.315411	valid's auc: 0.950403	valid's average_precision: 0.873369
[100]	train's binary_logloss: 0.323567	train's auc: 0.946524	train's average_precision: 0.947827	valid's binary_logloss: 0.292205	valid's auc: 0.951751	valid's average_precision: 0.875403
Early stopping, best iteration is:
[87]	train's binary_logloss: 0.335106	train's auc: 0.944893	train's average_precision: 0.946344	valid's binary_logloss: 0.304464	valid's auc: 0.951515	valid's average_precision: 0.876033
--- 評価結果（0.5, 閾値=0.500） ---
Accuracy: 0.8953
F1 Score: 0.7789
Recall: 0.8757
PR-AUC: 0.8760
Confusion Matrix:
[[1712  189]
 [  63  444]]
              precision    recall  f1-score   support

           0       0.96      0.90      0.93      1901
           1       0.70      0.88      0.78       507

    accuracy                           0.90      2408
   macro avg       0.83      0.89      0.86      2408
weighted avg       0.91      0.90      0.90      2408

--- GPT-4.1からの改善アドバイス ---
モデル評価結果・グラフを踏まえたLightGBMモデル改善アドバイス

主な課題

- クラス不均衡：3着以内（1）のサンプルが全体の21%程度であり、0（着外）に比べて大きく少ない（サポート数：1901 vs 507）。
- Precision（適合率）低め：1クラスのprecisionが0.70、recallが0.88。false positiveが多い。
- 学習曲線より：train/testのスコアギャップは大きくないが、データ量増加でまだ性能向上余地あり。
- ROC曲線はAUCが高そうだが、PR曲線は1クラスでprecisionがやや低めで推移している。

改善アドバイス

1. クラス不均衡対策
- パラメータscale_pos_weightやis_unbalance=Trueなど、LightGBMのクラス重み調整を活用し、少数クラス（3着以内）をより重視する学習を行う。
- SMOTE等のオーバーサンプリング、アンダーサンプリングも検討。

2. 特徴量（Feature）改善
- 重要特徴量の見直し。特徴量重要度を確認し、低重要度の特徴量削除や新規特徴量（コース、騎手、枠順の組み合わせ、馬場状態変化等）の追加を検討。
- 特徴量エンジニアリング（連系馬券向きの組み合わせ特徴や、直近成績の移動平均、指数化など）。

3. モデル・パラメータ最適化
- ハイパーパラメータ（num_leaves, max_depth, min_data_in_leaf等）のチューニングをGridSearchCVやOptuna等で実施し、過学習/未学習のバランスを取る。
- 交差検証（KFold, StratifiedKFold）でモデルの安定性・汎化性能を向上。

4. 評価指標の見直し
- 現状、F1やPR曲線も重視しているが、業務上「precision重視」か「recall重視」か再確認し、最適閾値を適応的に再設定。
- 3着以内をさらに細分化（1着/2着/3着）したマルチクラス分類も検討すると特徴抽出のヒントになる。

5. データ追加・品質向上
- 学習曲線から、学習データ量を増やすことでtestスコアがさらに上がる余地あり。過去データ、近年データなど追加も検討。
- 外部データ（天候、ラップタイム、パドックコメント等）も活用できる場合は検討。

6. アンサンブル
- LightGBM単体だけでなく、RandomForest・XGBoost・CatBoostなど他手法とのアンサンブルで精度向上を目指す。

まとめ
→ クラス不均衡対策と特徴量エンジニアリングを優先的に見直しつつ、パラメータ/データ追加/アンサンブルも段階的に導入していくのが効果的です。  
特に「precision向上」には誤検知抑制、特徴量の質向上、重み調整が重要です。
--- 評価結果（F1最大, 閾値=0.634） ---
Accuracy: 0.9140
F1 Score: 0.7924
Recall: 0.7791
PR-AUC: 0.8760
Confusion Matrix:
[[1806   95]
 [ 112  395]]
              precision    recall  f1-score   support

           0       0.94      0.95      0.95      1901
           1       0.81      0.78      0.79       507

    accuracy                           0.91      2408
   macro avg       0.87      0.86      0.87      2408
weighted avg       0.91      0.91      0.91      2408

--- GPT-4.1からの改善アドバイス ---
機械学習エンジニアとして、LightGBMによる競馬の3着以内予測モデルの評価と、グラフ（ROC曲線、PR曲線、学習曲線、混同行列）を踏まえた改善アドバイスを以下にまとめます。

## 現状分析
- **精度 0.9140、F1スコア 0.7924**
  - 全体的な精度は高いが、F1（特にRecall）が若干低め
- **混同行列**
  - 1（3着以内）クラスのRecall（0.78）が0クラス（0.95）より劣る＝取りこぼし（False Negative）が多い
- **ROC曲線**
  - AUCは高い（グラフより0.9以上）→モデル自体の識別力は十分
- **PR曲線**
  - 1クラスのPrecision-Recallバランスはまずまずだが、Recallがやや伸び悩み
- **学習曲線**
  - 学習・検証スコアが並行しつつ右肩上がりで、過学習の兆候なし。データ量増加で性能向上の余地あり

## 改善に向けたアドバイス

### 1. クラス不均衡対策
- **現状**：3着以内（1）が全体の2割程度と少数派
- **改善策**：
  - LightGBMの`scale_pos_weight`や`is_unbalance`パラメータを調整
  - もしくはSMOTE等で1クラスをオーバーサンプリング
  - 目的に応じてRecall重視で閾値を再調整（現状0.6343。F1よりRecall優先なら閾値を下げる）

### 2. 特徴量エンジニアリング
- **現状**：モデル識別力は高いが、Recallが伸びていない
- **改善策**：
  - 3着以内の馬が持つ特徴を深掘り（Feature Importanceで上位以外の特徴も見直す）
  - 連対率、直前成績、騎手成績、馬場適性など新しい特徴量の追加
  - カテゴリ変数のエンコーディング手法を見直す（Target Encodingなど）

### 3. モデルのアンサンブル
- **現状**：LightGBM単体
- **改善策**：
  - XGBoostやCatBoostなど他の勾配ブースティング系モデルとアンサンブル
  - ロジスティック回帰等の単純モデルとのスタッキングも有効

### 4. データボリュームの増強
- **現状**：学習曲線からデータ増加により更なる改善余地あり
- **改善策**：
  - 過去レースデータの追加
  - 外部データ（天気、オッズ、血統など）の活用

### 5. コスト関数/評価軸の見直し
- **現状**：F1最適化だが、Recall重視でもよい
- **改善策**：
  - 業務上「3着以内を漏らさない」ことが最重要ならRecall最大化へ切替
  - その場合、閾値やパラメータを再チューニング

---

## まとめ
1. クラス不均衡対策（パラメータ or データ調整）
2. 特徴量の追加・見直し
3. モデルのアンサンブル化
4. データ量の増加
5. Recall重視の評価指標・閾値設定

**→ まずはRecallを重視した閾値やクラス重みの再設定と、特徴量の拡充を優先すると効果が出やすいです。**

ご参考ください！
【実行所要時間】116.16秒
