--- 評価結果 ---
Accuracy: 0.8883
F1 Score: 0.7538
              precision    recall  f1-score   support

           0       0.91      0.94      0.93      8477
           1       0.80      0.71      0.75      2679

    accuracy                           0.89     11156
   macro avg       0.86      0.83      0.84     11156
weighted avg       0.89      0.89      0.89     11156


--- GPT-4.1からの改善アドバイス ---
モデル評価結果・各種グラフから、モデル改善のための主要なアドバイスをまとめます。

---

## 1. モデルの現状と課題

- **精度（Accuracy）**: 0.8883（全体的には高い）
- **F1スコア**: 0.7538（陽性クラスでのバランスはまずまず）
- **リコール（Recall, 1クラス）**: 0.71（3着以内の馬の検出漏れが約3割）
- **適合率（Precision, 1クラス）**: 0.80

→ 3着以内に入る馬（陽性クラス）の「取りこぼし」（リコール低下）が課題。全体精度は高いが、実運用ではリコール改善も重要。

---

## 2. ROC曲線・PR曲線から

- **ROCカーブ**: 曲線の形状は良好だが、閾値0.80付近でTPR/FPRのトレードオフが見える。
- **PRカーブ**: Precision-Recallのバランスは悪くないが、Recallを上げるとPrecisionが急速に低下。

---

## 3. 学習曲線から

- **学習・検証曲線の乖離**→若干のオーバーフィッティング傾向
  - 訓練データでのスコア＞検証データ
- **データ量増加による精度上昇余地**がややありそう

---

## 4. 混同行列から

- **False Negative（FN）**が多め（=3着以内を外すケース）
- **False Positive（FP）**も一定数存在（=3着以内でない馬を誤予測）

---

# 改善アドバイス（簡潔まとめ）

---

### 1. リコール改善（3着以内馬の見逃し減少）

- **閾値最適化再検討**  
  現在の最適閾値（0.7968）はPrecision重視寄り。Recall重視に再調整し、「取りこぼし」を減らすのも一案。
- **損失関数・クラス重み調整**  
  陽性クラス（3着以内）を重くする（`scale_pos_weight`や`class_weight`の調整）。
- **アンサンブルの多様化**  
  LightGBM、XGBoost以外のモデル（CatBoostやNN等）も組み合わせると予測傾向の幅が広がり、見逃し削減に寄与する場合あり。

---

### 2. 過学習対策・汎化性能向上

- **特徴量選択・エンジニアリング見直し**  
  不要・重複特徴量の削減 or 新特徴量追加でモデルの一般化能力を高める。
- **正則化・ドロップアウト強化**  
  パラメータ（L1/L2正則化等）やearly stopping、bagging系パラメータを調整。
- **データ拡張/外れ値対策**  
  データ数が足りない場合はデータ拡張（例：過去レース情報の追加、サンプル生成等）、異常値クリーニングも検討。

---

### 3. データ面の強化

- **学習データ量の増加**  
  学習曲線より、さらなるデータ追加で精度向上が見込める。
- **外部データ利用**  
  血統・調教師・騎手・馬場状態・直前オッズなど新たな特徴量導入も効果的。

---

### 4. 分析・実務面での運用アドバイス

- **リコール・Precisionのバランス調整**  
  実ビジネス要件に応じて、どちらを重視するか再定義し、しきい値や評価指標を運用目的に合わせて最適化。
- **誤分類事例の個別分析**  
  3着以内を外す事例（FN）・誤って3着以内と予測した事例（FP
