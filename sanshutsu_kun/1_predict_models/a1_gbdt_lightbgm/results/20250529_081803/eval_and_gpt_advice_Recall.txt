--- 評価結果 ---
Accuracy: 0.9045
F1 Score: 0.7894
              precision    recall  f1-score   support

           0       0.96      0.92      0.94      1901
           1       0.74      0.85      0.79       507

    accuracy                           0.90      2408
   macro avg       0.85      0.88      0.86      2408
weighted avg       0.91      0.90      0.91      2408


--- GPT-4.1からの改善アドバイス ---
モデルの評価と各種グラフを総合的に分析した上で、LightGBMによる競馬の3着以内予測モデル改善のためのアドバイスを簡潔にまとめます。

【1. 評価指標・全体傾向の確認】
- リコール（Recall）重視：0.85（3着以内を比較的多く拾えている）
- 適合率（Precision）：0.74（拾った3着以内のうち正解は7割強）
- F1スコア：0.79
- 精度（Accuracy）：0.90
- 混同行列より3着以内（陽性）の見逃し（FN）は少なめ、誤検知（FP）はやや多い
- ROC曲線はAUCが高い傾向（=判別力はある）
- PR曲線もまずまず（=陽性ラベルの再現性は高いが、Precisionに課題）

【2. 学習曲線・過学習傾向】
- 学習曲線（learning_curve.png）から、訓練・検証のスコア収束は見られるが、若干のギャップあり → わずかな過学習が疑われる

【3. 改善アドバイス】

① 特徴量の見直し
- Feature ImportanceやSHAP値の確認を行い、効果の薄い特徴量を削除や統合。新たな競馬特有特徴量（例: 騎手、馬場状態、過去実績、枠順など）を追加検討。

② データバランスの調整
- 3着以内のラベル（1）は全体の約2割程度で不均衡気味。SMOTE等のオーバーサンプリングやアンダーサンプリング、またはLightGBMの`scale_pos_weight`パラメータ調整でバランス改善。

③ モデルパラメータの最適化
- `num_leaves`や`min_data_in_leaf`、`max_depth`のチューニングで過学習を抑制しつつ再現率を維持。
- Early Stoppingやクロスバリデーションを活用、過学習対策を強化。

④ アンサンブル/他手法の検討
- XGBoostやCatBoost、あるいはロジスティック回帰・ランダムフォレストとのアンサンブルで精度・再現率バランス向上を検討。

⑤ 閾値調整の再検討
- 現在Recall重視（閾値0.54）だが、業務要件/目的に応じてF1やPrecision重視の閾値も検証し、最適なバランスを探索。

⑥ 可視化・解釈性強化
- SHAPやLIMEによる予測根拠の可視化で、モデルの説得力・納得感を向上。

【まとめ】
現状、3着以内をよく拾えているが、Precision向上と過学習抑制が今後の主な改善ポイントです。特徴量工夫・データバランス調整・パラメータ最適化・アンサンブル化で全体性能の底上げを目指しましょう。
