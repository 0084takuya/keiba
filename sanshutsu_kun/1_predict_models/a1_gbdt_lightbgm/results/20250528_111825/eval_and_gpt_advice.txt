--- 評価結果 ---
Accuracy: 1.0000
F1 Score: 1.0000
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      8465
           1       1.00      1.00      1.00      2691

    accuracy                           1.00     11156
   macro avg       1.00      1.00      1.00     11156
weighted avg       1.00      1.00      1.00     11156


--- GPT-4.1からの改善アドバイス ---
モデル改善のためのアドバイス（簡潔に）

1. 評価指標の異常に高い値に注意
- 精度・F1スコアが1.0000は、過学習（オーバーフィッティング）、もしくはデータや分割に問題がある可能性が高いです。特に、最適閾値が0.9969と極端に高い点も異常です。

2. ROC・PRカーブの確認
- ROC曲線・PR曲線ともにほぼ理想的すぎる形（ほぼ1.0）で、通常の現実的なデータでは起こりにくい挙動です。クラス分布やリーク（情報漏洩）を再確認してください。

3. 混同行列の確認
- 混同行列を見ると、全て正解（TN,TP＝全件）になっており、テストデータのラベルや分割方法に何らかの問題がある可能性が高いです。

4. 学習曲線の確認
- 学習曲線もほぼ誤差ゼロで推移しており、現実的ではありません。学習・検証データの独立性を再確認してください。

5. 改善案
- データのリーク（特徴量やターゲットの流出）が起きていないか厳密にチェック
- データ分割（クロスバリデーション、時系列分割など）の方法見直し
- 特徴量重要度・分布の再確認（予測に直結する変数が混じっていないか）
- クラス不均衡とその対策（サンプルの偏りの有無、ダウンサンプリングやSMOTE等の適用）
- モデルの汎化性能検証（外部データや直近データで再評価）

まとめ：
現状のスコアは不自然に高すぎるため、「データ分割・リーク・特徴量」を最優先で点検してください。モデルやアンサンブルの工夫より、まずはデータと分割方法を見直すべきです。
