--- 評価結果 ---
Accuracy: 0.9037
F1 Score: 0.7906
              precision    recall  f1-score   support

           0       0.96      0.91      0.94      1901
           1       0.73      0.86      0.79       507

    accuracy                           0.90      2408
   macro avg       0.85      0.89      0.86      2408
weighted avg       0.91      0.90      0.91      2408


--- GPT-4.1からの改善アドバイス ---
モデル評価結果および各種グラフ（ROC曲線、PR曲線、学習曲線、混合行列）を踏まえて、LightGBMによる競馬3着以内予測モデルの改善アドバイスを簡潔にまとめます。

### 1. 現状の評価から見える課題

- **Recall重視設定**：Recall（再現率）重視の閾値設定で、3着以内（ポジティブクラス）のRecallは0.86と高いが、Precision（適合率）は0.73と低めです。つまり「3着以内を多く拾えているが、外れも多い」状態です。
- **クラス不均衡**：混同行列からも分かる通り、3着以内(1)よりもそれ以外(0)が圧倒的に多い典型的なクラス不均衡データです。
- **ROC/PR曲線**：ROC曲線・PR曲線ともにAUCはまずまずですが、PR曲線は精度がRecall向上とトレードオフになっていることが読み取れます。
- **学習曲線**：train/testのスコアがあまり離れておらず、過学習の兆候は見られません（むしろややアンダーフィット傾向）。
- **混合行列**：False Positive（3着以内と予測したが実際は3着外）の数が多め。

---

### 2. 改善アドバイス

#### (1) 特徴量エンジニアリング
- **新しい特徴量の追加**：血統、騎手、調教、重馬場適性、レース展開、枠順など、競馬ならではの情報をさらに特徴量化してください。
- **特徴量の重要度分析**：LightGBMのfeature importanceを活用し、不要な特徴量を削減or主要特徴量を深掘りしましょう。

#### (2) クラス不均衡対策
- **損失関数の重み付け**：`scale_pos_weight`などを調整し、3着以内クラスをより重視する学習に設定。
- **サンプリング**：SMOTEなどによる少数クラスのオーバーサンプリングや、3着外のアンダーサンプリングで学習データをバランスさせるのも有効です。
- **閾値最適化**：業務要件に合わせて、F1スコアやPrecision-Recallバランスが最適となる閾値を再検討してください。

#### (3) モデルの高度化
- **アンサンブル**：LightGBM単体だけでなく、XGBoostやCatBoost、ランダムフォレストとのアンサンブル検討。
- **スタッキング**：予測力の高いモデルを複数組み合わせたスタッキングも有効です。
- **ハイパーパラメータチューニング**：learning_rate、num_leaves、max_depth などをGridSearchCVやOptuna等で最適化しましょう。

#### (4) 評価指標の見直し
- **業務的に重要な指標で再評価**：単なるRecall/F1だけでなく、Precision@K（上位K頭予測の適合率）や、回収率（実際の馬券購入シミュレーション）など競馬に即した評価も考慮してください。

#### (5) データ量の増強
- **学習曲線から**：データ量を増やすことで、さらなる精度向上が見込めます。過去のレースデータや外部データを積極的に追加しましょう。

---

### 3. まとめ（実施優先度）

1. **特徴量の見直し・追加**（最重要）
2. **クラス不均衡対策**（損失関数の重み・サンプリング・閾値調整）
3. **ハイパーパラメータ調整**
4. **アンサンブル/スタッキング導入**
5. **評価指標・閾値の業務最適化**
6. **学習データの拡充**

---

これらを順次試
