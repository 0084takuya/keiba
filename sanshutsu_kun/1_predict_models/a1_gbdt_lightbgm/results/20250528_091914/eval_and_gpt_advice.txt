--- 評価結果 ---
Accuracy: 0.8873
F1 Score: 0.7510
              precision    recall  f1-score   support

           0       0.91      0.94      0.93      8477
           1       0.80      0.71      0.75      2679

    accuracy                           0.89     11156
   macro avg       0.86      0.83      0.84     11156
weighted avg       0.88      0.89      0.88     11156


--- GPT-4.1からの改善アドバイス ---
モデル改善のためのアドバイス（評価指標・グラフより）

### 1. リコール（再現率）向上が課題
- クラス1（3着以内）のrecall: **0.71** と、precisionより低めです。  
→ 3着以内馬の見逃し（False Negative）が多い傾向です。

### 2. ROCカーブ・PRカーブの確認
- 【roc_curve.png】からAUC自体は高そうですが、閾値0.8付近でリコールが顕著に下がるパターンです。
- 【pr_curve.png】もprecision重視でリコール犠牲になっている形。

### 3. 学習曲線より
- 【learning_curve.png】を見るとtrain/testで大きな乖離はなく、過学習ではなさそう。  
- サンプル数増加による改善余地は小さい。

### 4. 混同行列から
- 【confusion_matrix.png】よりFalse Negative（本当は3着以内なのに外した馬）がそれなりに多い状態。

---

## 改善アドバイス（簡潔に）

### 1. 閾値（しきい値）の見直し
- 現在の最適閾値0.80はprecision重視すぎ。F1バランスやリコール重視（ex:0.7～0.75）も検討し、目的に合わせて調整を。

### 2. 特徴量の見直し・追加
- 3着以内に入る馬の特徴量が不足している可能性。  
  - 直前の調教や馬体重、展開・馬場適性等の情報追加を検討。
  - feature importanceを確認し、弱い特徴量は除外/強い特徴量は拡張。

### 3. アンサンブル手法の多様化
- 現状はGBDT系のみ。  
  - ロジスティック回帰やニューラルネットなど異種モデルの混合も検討すると更に補完性が高まる場合がある。

### 4. クラス不均衡対策
- 1（3着以内）が少数派の場合、  
  - サンプルウェイト調整
  - オーバーサンプリング（SMOTE等）、アンダーサンプリングを試す

### 5. 損失関数/評価指標の工夫
- 目的がリコール重視なら、カスタム評価指標や損失関数（Focal Loss等）も検討。

---

## まとめ
現状は「的中精度（precision）」重視で、3着以内の馬を拾いきれていません。  
**しきい値調整＋特徴量追加＋不均衡対策**が特に有効です。  
馬券種や目的（的中重視・回収率重視等）に合わせてリコール/precisionのバランスを再検討しましょう。
