--- 評価結果 ---
Accuracy: 0.9049
F1 Score: 0.7821
              precision    recall  f1-score   support

           0       0.95      0.93      0.94      1901
           1       0.76      0.81      0.78       507

    accuracy                           0.90      2408
   macro avg       0.85      0.87      0.86      2408
weighted avg       0.91      0.90      0.91      2408


--- GPT-4.1からの改善アドバイス ---
LightGBMモデルの評価結果と各種グラフ（ROC曲線、PR曲線、学習曲線、混同行列）を踏まえ、競馬の3着以内予測モデル改善のためのアドバイスを以下にまとめます。

---

### 1. 現状のモデル性能のポイント
- **精度（Accuracy）**が0.90と高い一方、**3着以内（クラス1）のRecallは0.81、Precisionは0.76、F1スコアは0.78**と、やや取りこぼし（False Negative）と誤検出（False Positive）が目立ちます。
- **混同行列**より、3着以内の正例（507件）のうち81%しか正しく検出できていません（FN=97）。
- **ROC曲線**はAUCが高そうで、全体の識別力は悪くありませんが、閾値調整の余地も感じられます。
- **PR曲線**もそこそこ良いが、Precision-Recallバランスの最適化の余地あり。
- **学習曲線**はtrain/testの差が大きくなければ過学習は顕著でないが、頭打ち感があれば特徴量やモデル自体の見直しが必要です。

---

### 2. 改善のための具体的アドバイス

#### （A）データ・特徴量の見直し
- **特徴量重要度分析**を実施し、寄与度の低い特徴量を除外、もしくは新たな特徴量（例：過去レースの着順安定度、馬場状態適性、騎手・厩舎の最近成績など）を追加してください。
- **カテゴリ変数のエンコーディング**手法（Label Encoding, Target Encoding等）を見直すことで精度向上の可能性があります。
- **データの不均衡**（3着以内が全体の約21%と少数派）に対し、SMOTEなどのオーバーサンプリング、またはクラス重み調整（`scale_pos_weight`などLightGBMのパラメータ）を検討。

#### （B）モデル・ハイパーパラメータ調整
- **閾値最適化**：現状0.412ですが、業務ニーズ（Precision重視 or Recall重視）に応じて再調整し、ベイズ最適化やグリッドサーチでF1やAUC-PR最大化を狙う。
- **ハイパーパラメータ調整**：`max_depth`, `num_leaves`, `min_child_samples`, `feature_fraction`, `bagging_fraction` などをGridSearchCVやOptuna等で最適化。
- **アンサンブル手法**：LightGBM単体で頭打ちの場合、StackingやBlending、他手法（CatBoost, XGBoost, ロジスティック回帰等）との組合せも有効。

#### （C）評価指標・検証手法の多角化
- **AUC-PR（Precision-Recall曲線下の面積）**を重視。少数クラスの予測性能を把握するにはAUC-ROCよりAUC-PRが適切な場合が多いです。
- **クロスバリデーション**や時系列KFold（競馬は時系列データなので）で汎化性能を安定して測定。

#### （D）追加的な工夫
- **予測確率のキャリブレーション**（Platt Scaling, Isotonic Regression等）を行い、確率値の信頼性を高める。
- **説明性（SHAP, LIME等）**でモデルの「なぜその馬を3着以内としたか」を可視化し、ドメイン知識と照合。

---

### 3. まとめ

- データの質・量と特徴量エンジニアリングを最優先で強化しましょう。
- クラス不均衡対策・評価指標の見直し・閾値最適化も重要です。
- モデルの改善はハイパーパラメータチューニング＋アンサンブルも併用すると効果的です。

---

#### 例：次の
