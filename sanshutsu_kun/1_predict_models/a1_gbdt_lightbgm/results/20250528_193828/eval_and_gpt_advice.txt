--- 評価結果 ---
Accuracy: 0.7593
F1 Score: 0.0140
              precision    recall  f1-score   support

         0.0       0.76      1.00      0.86      8438
         1.0       0.86      0.01      0.01      2696

    accuracy                           0.76     11134
   macro avg       0.81      0.50      0.44     11134
weighted avg       0.78      0.76      0.66     11134


--- GPT-4.1からの改善アドバイス ---
モデル改善のためのアドバイス（簡潔に）

### 1. 極端な不均衡データへの対処が必須
- 混同行列・評価指標から、3着以内（正例）の予測がほぼできていない（リコール0.01、F1スコア0.014）。
- **正例（3着以内）が極端に少ない or 負例に寄せすぎている**ため、閾値調整だけでは解決不可。

### 2. 精度（accuracy）以外の指標を重視
- 精度は高く見えるが、正例の検出性能が壊滅的（偽陽性・偽陰性のバランスが悪い）。
- **AUC・PR曲線（PRカーブ）**を重視し、リコール（再現率）、F1スコア、PR-AUCなどでモデル評価を。

### 3. 対策例
- **クラス重み付け/サンプル加重**：LightGBM/XGBoost/CatBoost すべてで `class_weight`/`scale_pos_weight` などを調整。
- **オーバーサンプリング**（SMOTE等）やアンダーサンプリングの利用。
- **閾値最適化**だけでなく、損失関数自体に不均衡対策を組み込む（例：Focal Loss, Balanced Logloss等）。

### 4. 特徴量見直し・モデル設計
- 3着以内の特徴が表現できる新たな特徴量設計（例：期待オッズ、過去実績、騎手/馬場適性など）。
- 特に「勝ち馬」「2着」「3着」ごとのサブモデルや、順位回帰型モデル（多クラス分類/順位予測）も検討。

### 5. 可視化・チューニング
- ROCカーブはAUCが高い場合でもPRカーブでベースライン近い場合、極端な不均衡の影響大。
- learning curveから、訓練/検証で大きなギャップがあれば過学習疑い。データ量増加や正則化も検討。

---

#### 【まとめ】
- 不均衡対策（クラス重み・サンプリング・損失関数）を最優先で
- 精度以外の指標（特にリコール/PRカーブ）で評価
- 特徴量見直しやモデル構造の再検討
- PRカーブ、混同行列を改善する方向でチューニング

---

このままでは「3着以内」の予測力が実運用に耐えないので、上記を優先的に対応しましょう。
