--- 評価結果 ---
Accuracy: 0.7576
F1 Score: 0.5826
              precision    recall  f1-score   support

           0       0.89      0.77      0.83      8477
           1       0.50      0.70      0.58      2679

    accuracy                           0.76     11156
   macro avg       0.69      0.74      0.71     11156
weighted avg       0.80      0.76      0.77     11156


--- GPT-4.1からの改善アドバイス ---
詳細な評価指標とグラフから、モデル改善のためのアドバイスをまとめます。

### 1. 現状の課題認識

- **再現率（recall）が高いが、適合率（precision）が低い（陽性クラス）**
  - 3着以内（=1）に入る馬の「見逃し」は少ないが、「誤検知」が多い（＝False Positiveが多い）。
- **クラス不均衡の影響**
  - 3着以内（=1）が全体の少数派（約24%）で、0:1=3:1程度。
- **ROC曲線：AUCは高くなさそう**
  - ROC曲線は大きく膨らんでおらず、モデルの判別力は限定的。
- **PR曲線：ベースラインよりは上**
  - ただし、適合率の伸びが鈍い。

---

### 2. 改善アドバイス

#### 特徴量・データ

- **有効な特徴量の探索・追加**
  - 重要特徴量のランキングを確認し、不要な変数を削除・新しい馬体情報や直近成績、騎手、馬場状態などを追加。
- **カテゴリ変数エンコーディングの見直し**
  - カテゴリ変数は適切にエンコードされているか（ターゲットエンコーディング・LE・OE等）。
- **外れ値・ノイズサンプルの除去**
  - イレギュラーなレースや明らかに勝ち目のない馬など、誤学習を誘発するデータを整理。

#### モデル

- **LightGBMのパラメータ最適化（特にクラス重み）**
  - `scale_pos_weight` や `is_unbalance` を調整し、少数派クラスの検出強化。
  - 過学習防止のため、木の深さや葉数も再調整。
- **閾値設定の再検討**
  - 0.43前後は「Recall重視」の設定。ビジネス要件や意図に応じて最適閾値を再探索。
- **アンサンブル手法の検討**
  - 他の手法（XGBoost、CatBoost、ロジスティック回帰等）とのスタッキングやバギング。

#### 学習方法・評価

- **サンプルの分布チェックと分割方法の見直し**
  - クロスバリデーションや時系列分割を使い、リークや偏りを防止。
- **SMOTEなどの不均衡対策**
  - 過学習に注意しつつ、オーバーサンプリングやアンダーサンプリングも検討。
- **誤分類サンプルの分析**
  - 予測失敗した馬の特徴を分析し、特徴量設計やモデル構造に反映。

---

### 3. その他Tips

- **モデルに新しい情報を積極的に投入**（馬体重、直前の調教タイム、天候、レース条件等）
- **結果解釈性を重視する場合はSHAPなども活用**
- **「高精度よりも高リコール重視」の意図なら、営業や実運用側と閾値・KPIのすり合わせを**

---

### まとめ

- クラス不均衡対策（重み付け・サンプリング・特徴量強化）が最優先
- モデルの過学習・データリーク防止も重要
- 閾値や評価指標の再設定も随時見直す

これらを順に試行・改善することで、より実用的な競馬予測モデルに近づくはずです。
