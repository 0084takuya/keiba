--- 評価結果 ---
Accuracy: 0.9140
F1 Score: 0.7924
              precision    recall  f1-score   support

           0       0.94      0.95      0.95      1901
           1       0.81      0.78      0.79       507

    accuracy                           0.91      2408
   macro avg       0.87      0.86      0.87      2408
weighted avg       0.91      0.91      0.91      2408


--- GPT-4.1からの改善アドバイス ---
機械学習エンジニアとして、LightGBMによる競馬の3着以内予測モデルの評価と、グラフ（ROC曲線、PR曲線、学習曲線、混同行列）を踏まえた改善アドバイスを以下にまとめます。

## 現状分析
- **精度 0.9140、F1スコア 0.7924**
  - 全体的な精度は高いが、F1（特にRecall）が若干低め
- **混同行列**
  - 1（3着以内）クラスのRecall（0.78）が0クラス（0.95）より劣る＝取りこぼし（False Negative）が多い
- **ROC曲線**
  - AUCは高い（グラフより0.9以上）→モデル自体の識別力は十分
- **PR曲線**
  - 1クラスのPrecision-Recallバランスはまずまずだが、Recallがやや伸び悩み
- **学習曲線**
  - 学習・検証スコアが並行しつつ右肩上がりで、過学習の兆候なし。データ量増加で性能向上の余地あり

## 改善に向けたアドバイス

### 1. クラス不均衡対策
- **現状**：3着以内（1）が全体の2割程度と少数派
- **改善策**：
  - LightGBMの`scale_pos_weight`や`is_unbalance`パラメータを調整
  - もしくはSMOTE等で1クラスをオーバーサンプリング
  - 目的に応じてRecall重視で閾値を再調整（現状0.6343。F1よりRecall優先なら閾値を下げる）

### 2. 特徴量エンジニアリング
- **現状**：モデル識別力は高いが、Recallが伸びていない
- **改善策**：
  - 3着以内の馬が持つ特徴を深掘り（Feature Importanceで上位以外の特徴も見直す）
  - 連対率、直前成績、騎手成績、馬場適性など新しい特徴量の追加
  - カテゴリ変数のエンコーディング手法を見直す（Target Encodingなど）

### 3. モデルのアンサンブル
- **現状**：LightGBM単体
- **改善策**：
  - XGBoostやCatBoostなど他の勾配ブースティング系モデルとアンサンブル
  - ロジスティック回帰等の単純モデルとのスタッキングも有効

### 4. データボリュームの増強
- **現状**：学習曲線からデータ増加により更なる改善余地あり
- **改善策**：
  - 過去レースデータの追加
  - 外部データ（天気、オッズ、血統など）の活用

### 5. コスト関数/評価軸の見直し
- **現状**：F1最適化だが、Recall重視でもよい
- **改善策**：
  - 業務上「3着以内を漏らさない」ことが最重要ならRecall最大化へ切替
  - その場合、閾値やパラメータを再チューニング

---

## まとめ
1. クラス不均衡対策（パラメータ or データ調整）
2. 特徴量の追加・見直し
3. モデルのアンサンブル化
4. データ量の増加
5. Recall重視の評価指標・閾値設定

**→ まずはRecallを重視した閾値やクラス重みの再設定と、特徴量の拡充を優先すると効果が出やすいです。**

ご参考ください！
