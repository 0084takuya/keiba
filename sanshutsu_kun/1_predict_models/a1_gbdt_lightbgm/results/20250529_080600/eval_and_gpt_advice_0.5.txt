--- 評価結果 ---
Accuracy: 0.8953
F1 Score: 0.7789
              precision    recall  f1-score   support

           0       0.96      0.90      0.93      1901
           1       0.70      0.88      0.78       507

    accuracy                           0.90      2408
   macro avg       0.83      0.89      0.86      2408
weighted avg       0.91      0.90      0.90      2408


--- GPT-4.1からの改善アドバイス ---
モデル評価結果・グラフを踏まえたLightGBMモデル改善アドバイス

主な課題

- クラス不均衡：3着以内（1）のサンプルが全体の21%程度であり、0（着外）に比べて大きく少ない（サポート数：1901 vs 507）。
- Precision（適合率）低め：1クラスのprecisionが0.70、recallが0.88。false positiveが多い。
- 学習曲線より：train/testのスコアギャップは大きくないが、データ量増加でまだ性能向上余地あり。
- ROC曲線はAUCが高そうだが、PR曲線は1クラスでprecisionがやや低めで推移している。

改善アドバイス

1. クラス不均衡対策
- パラメータscale_pos_weightやis_unbalance=Trueなど、LightGBMのクラス重み調整を活用し、少数クラス（3着以内）をより重視する学習を行う。
- SMOTE等のオーバーサンプリング、アンダーサンプリングも検討。

2. 特徴量（Feature）改善
- 重要特徴量の見直し。特徴量重要度を確認し、低重要度の特徴量削除や新規特徴量（コース、騎手、枠順の組み合わせ、馬場状態変化等）の追加を検討。
- 特徴量エンジニアリング（連系馬券向きの組み合わせ特徴や、直近成績の移動平均、指数化など）。

3. モデル・パラメータ最適化
- ハイパーパラメータ（num_leaves, max_depth, min_data_in_leaf等）のチューニングをGridSearchCVやOptuna等で実施し、過学習/未学習のバランスを取る。
- 交差検証（KFold, StratifiedKFold）でモデルの安定性・汎化性能を向上。

4. 評価指標の見直し
- 現状、F1やPR曲線も重視しているが、業務上「precision重視」か「recall重視」か再確認し、最適閾値を適応的に再設定。
- 3着以内をさらに細分化（1着/2着/3着）したマルチクラス分類も検討すると特徴抽出のヒントになる。

5. データ追加・品質向上
- 学習曲線から、学習データ量を増やすことでtestスコアがさらに上がる余地あり。過去データ、近年データなど追加も検討。
- 外部データ（天候、ラップタイム、パドックコメント等）も活用できる場合は検討。

6. アンサンブル
- LightGBM単体だけでなく、RandomForest・XGBoost・CatBoostなど他手法とのアンサンブルで精度向上を目指す。

まとめ
→ クラス不均衡対策と特徴量エンジニアリングを優先的に見直しつつ、パラメータ/データ追加/アンサンブルも段階的に導入していくのが効果的です。  
特に「precision向上」には誤検知抑制、特徴量の質向上、重み調整が重要です。
