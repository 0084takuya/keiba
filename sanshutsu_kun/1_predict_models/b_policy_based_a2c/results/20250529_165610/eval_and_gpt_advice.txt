Accuracy: 0.7970
F1 Score: 0.0000
Recall: 0.0000
              precision    recall  f1-score   support

           0       0.80      1.00      0.89       636
           1       0.00      0.00      0.00       162

    accuracy                           0.80       798
   macro avg       0.40      0.50      0.44       798
weighted avg       0.64      0.80      0.71       798

--- GPT-4.1からの改善アドバイス ---
モデル評価とグラフから、以下の点が読み取れます：

### 問題点の整理

- **精度（Accuracy）は高い(0.7970)が、F1・Recallは0**
  - モデルが「3着以内」と判定すべきクラス（1）を全く予測できていない（=全て0と判定している）ため、RecallとF1スコアが0になっています。
  - 混同行列を見ると、Positive（1）を真陽性として1件も当てていません。
- **ROC曲線・PR曲線**
  - ROCカーブはほぼダイアゴナル（無判別）に近い形です。AUCも高くないはずです。
  - PRカーブもベースラインに近い形で、クラス1の判定能力がほぼありません。
- **学習曲線**
  - 学習・検証ともに精度高めで推移しているものの、Recall/F1が改善していないなら、クラス不均衡により「全部0」と答えた方が損失が低い状況です。

---

## 改善のためのアドバイス

### 1. クラス不均衡対策が最優先

- **3着以内馬（=1）が全体の20%しかいない**
  - →「全部0」と答えても80%当たるため、モデルがバイアスされている。
- **対策例**
  - 損失関数にクラス重みを付与して「1」を重視（例：`class_weight`や`weighted cross entropy`）
  - オーバーサンプリング（SMOTE等）やアンダーサンプリング
  - 3着以内馬のデータを「増やす」工夫

### 2. 評価指標の見直し

- **AccuracyではなくRecall/F1やAUCで最適化する**
  - モデル選択やEarly stopping時も、RecallやF1スコアを重視

### 3. 出力閾値の調整

- **0.5固定でなく、閾値をチューニング**
  - PRカーブやROCカーブから最適閾値を再検討

### 4. 特徴量・モデルの見直し

- **特徴量の分布や有用性を再確認**
  - 重要度が低すぎる特徴量の除去や追加
- **モデル設計（A2Cのネットワーク構造など）の再調整**

---

## まとめ

1. **クラス1（3着以内）を正しく学習・判定できるよう、クラス不均衡対策を必ず実施してください。**
2. **損失関数、EarlyStopping、評価指標を「Recall」や「F1」に合わせて見直しましょう。**
3. **閾値調整・特徴量/モデルチューニングも並行して行いましょう。**

これを行うことで、RecallやF1スコアが大幅に改善する可能性が高いです。
