【評価対象データ】
・対象期間: 直近1080日分
・使用特徴量:
  - 馬齢（BAREI）
  - 性別コード（SEIBETSU_CODE）
  - 馬体重（BATAIJU）
  - 直近体重変化（BATAIJU_DIFF）
  - 同レース内馬体重順位（BATAIJU_RANK）
  - 同レース内人気順位（NINKI_RANK）
  - 負担重量（FUTAN_JURYO）
  - 単勝人気順（TANSHO_NINKIJUN）
  - 枠順（WAKUBAN）
  - 距離（KYORI）
  - 芝/ダート（トラックコード）（TRACK_CODE）
  - 頭数（SHUSSO_TOSU）
  - 騎手3着以内率（KISHU_3IN_RATE）
  - 馬場状態（TENKO_CODE）
  - 調教師3着以内率（CHOKYOSHI_3IN_RATE）
  - 父系統ID（FATHER_LINEAGE）
  - 馬過去5走3着以内率（UMA_5R_3IN_RATE）
  - コース適性3着以内率（COURSE_3IN_RATE）
  - コース×馬過去5走3着以内率（COURSE_UMA_5R_3IN_RATE）
  - 父系統ターゲットエンコーディング（FATHER_LINEAGE_TE）
  - トラックコードターゲットエンコーディング（TRACK_CODE_TE）
  - 馬体重×距離（BATAIJU_KYORI）
  - 馬齢×負担重量（BAREI_FUTAN_JURYO）
  - 騎手×調教師ターゲットエンコーディング（KISHU_CHOKYOSHI_TE）
  - 馬×コースターゲットエンコーディング（UMA_COURSE_TE）
  - レース間隔（日数）（RACE_KANKAKU）
  - 馬場状態（良=1, それ以外=0）（TENKO_FINE）

--- 評価結果 ---
Accuracy: 0.9431
F1 Score: 0.8419
              precision    recall  f1-score   support

           0       0.93      1.00      0.97      8832
           1       0.99      0.73      0.84      2302

    accuracy                           0.94     11134
   macro avg       0.96      0.87      0.90     11134
weighted avg       0.95      0.94      0.94     11134

--- PRカーブからF1最大化となる最適閾値: 0.291 ---
--- 最適閾値での再評価 ---
Accuracy: 0.9953
F1 Score: 0.9888
              precision    recall  f1-score   support

           0       1.00      0.99      1.00      8832
           1       0.98      1.00      0.99      2302

    accuracy                           1.00     11134
   macro avg       0.99      1.00      0.99     11134
weighted avg       1.00      1.00      1.00     11134


--- GPT-4.1からの改善アドバイス ---
モデル評価と各種グラフを踏まえた改善アドバイス
モデル評価・グラフのポイントまとめ

1. 評価指標の状況
- デフォルト閾値: 精度0.94、F1=0.84。リコール(1クラス)が0.73とやや低い。
- PRカーブで最適閾値(0.291)では、精度・F1ともにほぼ1.0。ただし、現実的には高すぎる可能性あり（データリーク等も要確認）。

2. ROCカーブ
- 全体的にAUCが高そうで、分類性能は良好。
- ただし閾値依存性があり、実運用時の閾値設定に注意。

3. PRカーブ
- クラス不均衡（3着以内: 1, それ以外: 0）でも高い精度。
- しかし、異常に高いF1と精度はデータやラベルにバイアス、リークの可能性も疑うべき。

4. 学習曲線
- 学習・検証誤差ともに早期に収束。明確な過学習や未学習は見られない。
- ただし、データサイズが増えても大きく性能向上しておらず、モデルの表現力がデータ量に対し十分であるかも要検討。

5. 混同行列
- 最適閾値では、ほぼ全件正解。実データでは過学習やリークの疑いも。

改善アドバイス

1. データリーク/ラベルリーク確認
- あまりに高すぎる精度・F1は「未来情報」やラベルに直結する特徴量が含まれているリスクあり。
- 特に「同レース内人気順位」「単勝人気順」「騎手3着以内率」など、結果発表後やオッズに依存するものは、学習時点で利用可能な情報か厳密に見直す。
- 直近体重変化なども未来情報でないか再確認。

2. 特徴量の見直し・整理
- 予測時点で取得できない情報は除去。
- 既存の特徴量から「集約」や「派生」特徴量を追加することで、より一般化性能向上を狙う。
- カテゴリ変数の適切なエンコーディング（ターゲットエンコーディング過多になっていないか等）もチェック。

3. モデル構造・手法の見直し
- DQN（Deep Q-Network）は本来強化学習用。分類タスクには一般的にXGBoostやCatBoost、MLP/NNなどが適切。
- モデル選択肢を広げて、他手法（ランダムフォレスト/LightGBM/NN等）でも比較検証を行う。

4. クラス不均衡対策
- 3着以内（1）が少数なら、再サンプリング、損失関数の重み付け、Focal Loss等の導入も検討。

5. モデルの汎化性能評価
- クロスバリデーションや直近の未学習レースに対する「将来予測テスト」を実施し、過学習やリークがないか再度確認。

6. 現場観点でのKPI見直し
- 実際の運用では「的中率（precision）」だけでなく「回収率」「単勝・複勝での実益」もKPIに加えて評価することを推奨。

まとめ
現状のモデルは「過剰に高い指標」が示す通り、データや特徴量のリーク、モデル・評価プロセスの見直しが最優先です。まずは予測時点で利用できる情報だけに絞り、再学習・再評価をし、モデル手法や損失関数の最適化も並行して進めてください。  
また、現場運用の目的に直結した評価指標（回収率等）でも実績を確認しましょう。

---

もし、より具体的な特徴量ごとの分析
