【評価対象データ】
・対象期間: 直近3年分
・使用特徴量:
  - 馬齢（BAREI）
  - 性別コード（SEIBETSU_CODE）
  - 馬体重（BATAIJU）
  - 負担重量（FUTAN_JURYO）
  - 単勝人気順（TANSHO_NINKIJUN）
  - 距離（KYORI）
  - 芝/ダート（トラックコード）（TRACK_CODE）
  - 頭数（SHUSSO_TOSU）
  - 騎手3着以内率（KISHU_3IN_RATE）
  - 馬場状態（TENKO_CODE）
  - 調教師3着以内率（CHOKYOSHI_3IN_RATE）
  - 父系統ID（FATHER_LINEAGE）
  - 馬過去5走3着以内率（UMA_5R_3IN_RATE）
  - コース適性3着以内率（COURSE_3IN_RATE）
  - コース×馬過去5走3着以内率（COURSE_UMA_5R_3IN_RATE）
  - 父系統ターゲットエンコーディング（FATHER_LINEAGE_TE）
  - トラックコードターゲットエンコーディング（TRACK_CODE_TE）
  - 馬体重×距離（BATAIJU_KYORI）
  - 馬齢×負担重量（BAREI_FUTAN_JURYO）
  - 騎手×調教師ターゲットエンコーディング（KISHU_CHOKYOSHI_TE）
  - 馬×コースターゲットエンコーディング（UMA_COURSE_TE）
  - レース間隔（日数）（RACE_KANKAKU）
  - 馬場状態（良=1, それ以外=0）（TENKO_FINE）

--- 評価結果 ---
Accuracy: 0.9308
F1 Score: 0.8539
              precision    recall  f1-score   support

           0       0.98      0.93      0.95      6165
           1       0.79      0.93      0.85      1715

    accuracy                           0.93      7880
   macro avg       0.88      0.93      0.90      7880
weighted avg       0.94      0.93      0.93      7880

--- PRカーブからF1最大化となる最適閾値: 0.491 ---
--- 最適閾値での再評価 ---
Accuracy: 0.9308
F1 Score: 0.8565
              precision    recall  f1-score   support

           0       0.98      0.93      0.95      6165
           1       0.78      0.95      0.86      1715

    accuracy                           0.93      7880
   macro avg       0.88      0.94      0.91      7880
weighted avg       0.94      0.93      0.93      7880


--- GPT-4.1からの改善アドバイス ---
モデルの評価指標・混同行列・学習曲線・ROC/PRカーブを総合的に見て、以下の改善ポイントとアドバイスを簡潔にまとめます。

---

### 1. クラス不均衡への対応強化
- **現状**：混同行列・precision/recallから、3着以内(=1)の馬に対するprecisionがやや低め（0.78～0.79）。全体的に「3着外」を多く正しく判定する一方、「3着以内」の誤判定が目立つ。
- **対策**：
  - **損失関数の重み付け**（クラスバランス考慮、`class_weight`の利用やFocal Loss導入）。
  - **データ拡張/アンダーサンプリング/オーバーサンプリング**（SMOTE等）による3着以内サンプルの強化。

---

### 2. モデルの過学習・汎化性能
- **学習曲線**：train/valのlossが大きく乖離していないため、致命的な過学習は見られませんが、もう少しvalスコアを伸ばせる余地があります。
- **対策**：
  - **Dropout率/正則化項の調整**、**Early Stopping**の再検討。
  - **学習データのシャッフルやクロスバリデーション**による汎化性能向上。

---

### 3. 特徴量の見直し
- **現状**：多様な特徴量（ターゲットエンコーディング含む）が利用されており、情報量は十分。ただし、強い相関や冗長な特徴量がある場合、逆効果になることも。
- **対策**：
  - **特徴量重要度（Permutation ImportanceやSHAP値）を可視化**し、冗長／効果の薄い特徴量を削減。
  - **新たな特徴量の追加**（例：馬の成長曲線、調教タイム、直前追切評価など）や、特徴量エンジニアリングの強化。

---

### 4. モデルアーキテクチャ・アルゴリズムの再検討
- **現状**：DQN（深層強化学習系）での分類タスク。DQN自体は強化学習用なので、分類モデルとしてはややオーバースペックまたは最適でない場合あり。
- **対策**：
  - **LightGBMやCatBoost等の勾配ブースティング**、**TabNetなどテーブルデータ向けDNN**もベンチマークとして試す。
  - **アンサンブル**（複数モデルの組み合わせ）も検討。

---

### 5. 閾値最適化・実運用設計
- **現状**：最適閾値(0.491)の選定は適切。
- **対策**：
  - **ビジネス要件（予想を当てる vs.穴馬を狙う 等）に応じて閾値・評価指標（Precision/Recall/F1）を再調整**。

---

### 6. ROC/PRカーブの活用
- **ROCカーブ**：AUCが高そうなので、モデル自体の識別能力は高い。
- **PRカーブ**：陽性（3着以内）サンプルが少ない場合、PRカーブ（特にAUPRC）が重要。AUPRCも確認しつつ、閾値調整の指標とする。

---

## 総括

- **クラス不均衡対策**と**特徴量の見直し**が最優先課題。
- 学習データの増強・損失関数の工夫・モデルの多様化（勾配ブースティングやアンサンブル）も効果的。
- 実運用の目的（精度、的中率、回収率等）に合わせた評価指標・閾値設計も重要。

---

以上を踏まえ、段階的に改善に取り組んでください！
