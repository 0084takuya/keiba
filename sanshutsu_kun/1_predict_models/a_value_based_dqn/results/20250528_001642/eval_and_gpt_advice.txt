【評価対象データ】
・対象期間: 直近3年分
・使用特徴量:
  - 馬齢（BAREI）
  - 性別コード（SEIBETSU_CODE）
  - 馬体重（BATAIJU）
  - 負担重量（FUTAN_JURYO）
  - 単勝人気順（TANSHO_NINKIJUN）
  - 距離（KYORI）
  - 芝/ダート（トラックコード）（TRACK_CODE）
  - 頭数（SHUSSO_TOSU）
  - 騎手3着以内率（KISHU_3IN_RATE）
  - 馬場状態（TENKO_CODE）
  - 調教師3着以内率（CHOKYOSHI_3IN_RATE）
  - 父系統ID（FATHER_LINEAGE）
  - 馬過去5走3着以内率（UMA_5R_3IN_RATE）
  - コース適性3着以内率（COURSE_3IN_RATE）
  - コース×馬過去5走3着以内率（COURSE_UMA_5R_3IN_RATE）
  - 父系統ターゲットエンコーディング（FATHER_LINEAGE_TE）
  - トラックコードターゲットエンコーディング（TRACK_CODE_TE）
  - 馬体重×距離（BATAIJU_KYORI）
  - 馬齢×負担重量（BAREI_FUTAN_JURYO）
  - 騎手×調教師ターゲットエンコーディング（KISHU_CHOKYOSHI_TE）
  - 馬×コースターゲットエンコーディング（UMA_COURSE_TE）
  - レース間隔（日数）（RACE_KANKAKU）
  - 馬場状態（良=1, それ以外=0）（TENKO_FINE）

--- 評価結果 ---
Accuracy: 0.8874
F1 Score: 0.6595
              precision    recall  f1-score   support

           0       0.88      0.99      0.93      6165
           1       0.97      0.50      0.66      1715

    accuracy                           0.89      7880
   macro avg       0.92      0.75      0.80      7880
weighted avg       0.90      0.89      0.87      7880

--- PRカーブからF1最大化となる最適閾値: 0.374 ---
--- 最適閾値での再評価 ---
Accuracy: 0.9176
F1 Score: 0.8227
              precision    recall  f1-score   support

           0       0.96      0.93      0.95      6165
           1       0.77      0.88      0.82      1715

    accuracy                           0.92      7880
   macro avg       0.87      0.90      0.88      7880
weighted avg       0.92      0.92      0.92      7880


--- GPT-4.1からの改善アドバイス ---
モデルの現状分析と改善方法（DQNによる競馬3着以内予測）

【現状の評価まとめ】

- デフォルト閾値時
  - 精度: 0.8874
  - F1: 0.6595（positiveのrecall: 0.50, precision: 0.97）
  - 3着以内（positiveクラス）の取りこぼし多い（recall低い）

- 最適閾値（0.374）時
  - 精度: 0.9176
  - F1: 0.8227（positiveのrecall: 0.88, precision: 0.77）
  - バランス良化。3着以内の拾い漏れ減少。

- ROC曲線：AUC高め、良好。
- PR曲線：閾値調整でF1大幅改善。
- Learning Curve: train/validのgap小、過学習はあまり見られない。
- 混同行列: 最適閾値で偽陽性（3着以内でないのに予測）が多少増えるが、偽陰性（3着以内を見逃す）が大きく減る。

【モデル改善のためのポイント】

1. **閾値調整は必須**
   - デフォルト0.5だと「3着以内」を見逃しやすい（recall低い）ので、実運用では必ずPR曲線ベースで最適閾値を定める。

2. **クラス不均衡対策**
   - 3着以内（positive）が全体の2割強程度で不均衡。  
   ⇒ loss関数に重み付与 or サンプルのアップサンプリング/ダウンサンプリング検討。

3. **特徴量エンジニアリング**
   - 既に多様な特徴（馬、騎手、調教師、コース、エンコーディング等）を網羅しているが、以下も検討余地あり
     - レース当日の天気、気温
     - 直近レースの着順・時計など「フォーム」
     - 馬の血統・母系の追加情報
     - マルチヘッドアテンションによる特徴間関係の強調

4. **モデル多様化・融合**
   - DQN（強化学習的な枠組み？）以外に、LightGBMなど決定木系モデルや深層学習（MLP/TabNet）とのアンサンブルも精度向上に有効。

5. **説明性・Feature Importanceの分析**
   - どの特徴が重要かを確認し、不要な特徴の削減や、より情報量の多い特徴の追加を検討。

6. **「馬券」的な評価軸も導入**
   - 単なるF1/accuracyでなく、実際に「3着以内推奨馬」で馬券を買った場合の回収率・的中率にも着目し、閾値や予測結果の使い方を最適化（例：上位N頭のみを推奨）。

7. **データ拡張・検証**
   - 近年のデータに偏りすぎていないか、年度ごとの精度変化や、G1/G2/G3/条件戦などレース種別ごとの評価もチェック。

【具体的な次ステップ例】

- PRカーブベースで「閾値0.37程度」で予測運用する。
- positive class（3着以内）にloss重みを加えた再学習。
- feature importance（SHAPなど）で特徴量の見直し・追加。
- 他手法（決定木系、MLP等）とのアンサンブル比較。
- 馬券シミュレーションで実戦的な指標も確認。

---

**まとめ**  
現状、特徴量・学習パイプラインは一定水準にありますが、「閾値調整」「クラス不均衡対策」「特徴量の質向上」「アンサンブル」「説明性分析」「実運用評価指標の追加」が短期的な改善ポイントです。  
最適閾値運用＋重み付きlossによる再学習をまずは強く推奨します。
